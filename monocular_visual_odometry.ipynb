{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c64e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib.visualization import plotting\n",
    "from lib.visualization.video import play_trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f13adc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualOdometry():\n",
    "    def __init__(self, data_dir):\n",
    "        self.K, self.P = self.load_calib(os.path.join(data_dir, 'calib.txt'))\n",
    "        self.gt_poses = self.load_poses(os.path.join(data_dir, 'poses.txt'))\n",
    "        self.images = self.load_images(os.path.join(data_dir, 'image_l'))\n",
    "        self.orb = cv2.ORB_create(3000)\n",
    "        FLANN_INDEX_KTREE = 6\n",
    "        index_params = dict(algorithm=FLANN_INDEX_KTREE, table_number=6, key_size=12,\n",
    "                           multi_probe_level=1)\n",
    "        search_params = dict(checks=50)\n",
    "        self.flann = cv2.FlannBasedMatcher(indexParams=index_params, \n",
    "                                          searchParams=search_params)\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_calib(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            params = np.fromstring(f.readline(), dtype=np.float64, sep=' ')\n",
    "            P = np.reshape(params, (3, 4))\n",
    "            K = P[0:3, 0:3]\n",
    "        return K, P\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_poses(filepath):\n",
    "        poses = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                T = np.fromstring(line, dtype=np.float64, sep=' ')\n",
    "                T = T.reshape(3, 4)\n",
    "                T = np.vstack((T, [0, 0, 0, 1]))\n",
    "                poses.append(T)\n",
    "        return poses\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_images(filepath):\n",
    "        image_paths = [\n",
    "            os.path.join(filepath, file) for file in sorted(os.listdir(filepath))\n",
    "        ] \n",
    "        return [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in image_paths]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def transform_matrix(R, t):\n",
    "        T = np.eye(4, dtype=np.float64)\n",
    "        T[:3,:3] = R\n",
    "        T[:3, 3] = t\n",
    "        return T\n",
    "    \n",
    "    def get_matches(self, i):\n",
    "        \n",
    "        # Detects and computes keypoints \n",
    "        \n",
    "        kp1, des1 = self.orb.detectAndCompute(self.images[i-1], None)\n",
    "        kp2, des2 = self.orb.detectAndCompute(self.images[i], None)\n",
    "        \n",
    "        matches = self.flann.knnMatch(des1, des2, k=2)\n",
    "        \n",
    "        good = []\n",
    "        try:\n",
    "            for m, n in matches:\n",
    "                if m.distance < 0.8 * n.distance:\n",
    "                    good.append(m)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        draw_params = dict(\n",
    "        matchColor=-1, singlePointColor=None, matchesMask=None,\n",
    "        flags=2)\n",
    "        \n",
    "        img = cv2.drawMatches(self.images[i], kp1, self.images[i-1],\n",
    "                             kp2, good, None, **draw_params)\n",
    "        cv2.imshow(\"image\", img)\n",
    "        cv2.waitKey(200)\n",
    "        \n",
    "        # Get image points from the good matches\n",
    "        \n",
    "        q1 = np.float32([kp1[m.queryIdx].pt for m in good])\n",
    "        q2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "        \n",
    "        return q1, q2\n",
    "    \n",
    "    def get_pose(self, q1, q2):\n",
    "        \n",
    "        # Calculates transformation matrix\n",
    "        \n",
    "        E, _ = cv2.findEssentialMat(q1, q2 ,self.K, threshold=1)\n",
    "        \n",
    "        R, t = self.decomp_essential_mat(E, q1, q2)\n",
    "        \n",
    "        transformation_matrix = self.transform_matrix(R, np.squeeze(t))\n",
    "        \n",
    "        return transformation_matrix\n",
    "    \n",
    "    def decomp_essential_mat(self, E, q1, q2):\n",
    "        \n",
    "        # Returns correct R and t matrices\n",
    "        \n",
    "        def sum_z_cal_relative_scale(R, t):\n",
    "            T = self.transform_matrix(R, t)\n",
    "            \n",
    "            # Turn into projection matrix\n",
    "            P = np.matmul(np.concatenate((self.K, np.zeros((3,1))), axis=1), T)\n",
    "            \n",
    "            # Triangulate to 3D \n",
    "            hom_Q1 = cv2.triangulatePoints(self.P, P, q1.T, q2.T)\n",
    "            \n",
    "            # Also seen from frame 2\n",
    "            hom_Q2 = np.matmul(T, hom_Q1)\n",
    "            \n",
    "            # Un-homogenize\n",
    "            uhom_Q1 = hom_Q1[:3, :] / hom_Q1[3, :]\n",
    "            uhom_Q2 = hom_Q2[:3, :] / hom_Q2[3, :]\n",
    "            \n",
    "            # Find the number of points that has positive z coordinate in both cameras\n",
    "            \n",
    "            sum_pos_z_Q1 = sum(uhom_Q1[2, :] > 0)\n",
    "            sum_pos_z_Q2 = sum(uhom_Q2[2, :] > 0)\n",
    "            \n",
    "            # Form point pairs and calculate the relative scale\n",
    "            \n",
    "            relative_scale = np.mean(np.linalg.norm(uhom_Q1.T[:-1] - uhom_Q1.T[1:], axis=-1)/\n",
    "                                     np.linalg.norm(uhom_Q2.T[:-1] - uhom_Q2.T[1:], axis=-1))\n",
    "            return sum_pos_z_Q1 + sum_pos_z_Q2, relative_scale\n",
    "        \n",
    "        R1, R2, t = cv2.decomposeEssentialMat(E)\n",
    "        t = np.squeeze(t)\n",
    "        \n",
    "        pairs = [[R1, t], [R1, -t], [R2, t], [R2, -t]]\n",
    "        \n",
    "        z_sums = []\n",
    "        relative_scales = []\n",
    "        for R, t in pairs:\n",
    "            z_sum, scale = sum_z_cal_relative_scale(R, t)\n",
    "            z_sums.append(z_sum)\n",
    "            relative_scales.append(scale)\n",
    "        \n",
    "        idx = np.argmax(z_sum)\n",
    "        right_pair = pairs[idx]\n",
    "        relative_scale = relative_scales[idx]\n",
    "        R1, t = right_pair\n",
    "        t = t * relative_scale\n",
    "        \n",
    "        return [R1, t]        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e9e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    data_dir = 'KITTI_sequence_1'\n",
    "    vo = VisualOdometry(data_dir)\n",
    "    \n",
    "    play_trip(vo.images)\n",
    "    \n",
    "    gt_path = []\n",
    "    est_path = []\n",
    "    for i, gt_pose in enumerate(tqdm(vo.gt_poses, unit='pose')):\n",
    "        if i == 0:\n",
    "            cur_pose = gt_pose\n",
    "        else:\n",
    "            q1, q2 = vo.get_matches(i)\n",
    "            trans = vo.get_pose(q1, q2)\n",
    "            cur_pose = np.matmul(cur_pose, np.linalg.inv(trans))\n",
    "        gt_path.append((gt_pose[0,3], gt_pose[2,3]))\n",
    "        est_path.append((cur_pose[0,3], cur_pose[2,3]))\n",
    "    plotting.visualize_paths(gt_path, est_path, \"Visual Odometry\",\n",
    "                            file_out=os.path.basename(data_dir)+\".html\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49adbfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 51/51 [00:20<00:00,  2.49pose/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86c391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
